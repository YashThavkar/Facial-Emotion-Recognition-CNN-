{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5608806-7782-4b76-b1f7-c2a74e0d769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_preprocessing in c:\\users\\yash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\yash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras_preprocessing) (2.1.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\yash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras_preprocessing) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split-folders in c:\\users\\yash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_preprocessing\n",
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a7f324-09eb-4a36-9543-eeb5d9e4a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired accuracy and validation_accuracy > 83%\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf46ba83-047d-4c4c-bbfd-34407abbca0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45304 images belonging to 7 classes.\n",
      "Found 6286 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Corrected paths (double-check if it's 'images/images' or just 'images')\n",
    "TRAINING_DIR = 'images/FER-Balanced/train'\n",
    "VALIDATION_DIR = 'images/FER-Balanced/test'\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(56, 56),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=(56, 56),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2155e9bb-4ddf-4b0e-868d-0a66b4408384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m590,336\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m3,591\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,478,727</span> (17.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,478,727\u001b[0m (17.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,474,759</span> (17.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,474,759\u001b[0m (17.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(56, 56,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d43341-d1a1-4491-b21d-b9a79925c7ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1797 - loss: 2.1729\n",
      "Epoch 1: val_accuracy improved from -inf to 0.20041, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m972s\u001b[0m 1s/step - accuracy: 0.1797 - loss: 2.1727 - val_accuracy: 0.2004 - val_loss: 1.9626\n",
      "Epoch 2/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:47\u001b[0m 1s/step - accuracy: 0.2188 - loss: 1.8719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.20041\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.2188 - loss: 1.8719 - val_accuracy: 0.1996 - val_loss: 1.9630\n",
      "Epoch 3/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995ms/step - accuracy: 0.2146 - loss: 1.9805\n",
      "Epoch 3: val_accuracy improved from 0.20041 to 0.26180, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 1s/step - accuracy: 0.2146 - loss: 1.9805 - val_accuracy: 0.2618 - val_loss: 1.8567\n",
      "Epoch 4/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:29\u001b[0m 977ms/step - accuracy: 0.2344 - loss: 1.9207\n",
      "Epoch 4: val_accuracy did not improve from 0.26180\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.2344 - loss: 1.9207 - val_accuracy: 0.2607 - val_loss: 1.8597\n",
      "Epoch 5/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - accuracy: 0.2628 - loss: 1.8828\n",
      "Epoch 5: val_accuracy improved from 0.26180 to 0.33546, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 1s/step - accuracy: 0.2628 - loss: 1.8827 - val_accuracy: 0.3355 - val_loss: 1.7488\n",
      "Epoch 6/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:40\u001b[0m 993ms/step - accuracy: 0.3438 - loss: 1.7961\n",
      "Epoch 6: val_accuracy improved from 0.33546 to 0.33642, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.3438 - loss: 1.7961 - val_accuracy: 0.3364 - val_loss: 1.7384\n",
      "Epoch 7/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - accuracy: 0.3144 - loss: 1.7675\n",
      "Epoch 7: val_accuracy improved from 0.33642 to 0.40482, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 1s/step - accuracy: 0.3144 - loss: 1.7674 - val_accuracy: 0.4048 - val_loss: 1.5612\n",
      "Epoch 8/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:34\u001b[0m 984ms/step - accuracy: 0.4062 - loss: 1.6699\n",
      "Epoch 8: val_accuracy did not improve from 0.40482\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.4062 - loss: 1.6699 - val_accuracy: 0.4042 - val_loss: 1.5600\n",
      "Epoch 9/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990ms/step - accuracy: 0.3559 - loss: 1.6605\n",
      "Epoch 9: val_accuracy improved from 0.40482 to 0.43367, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 1s/step - accuracy: 0.3559 - loss: 1.6605 - val_accuracy: 0.4337 - val_loss: 1.5111\n",
      "Epoch 10/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:01\u001b[0m 1s/step - accuracy: 0.4062 - loss: 1.6056\n",
      "Epoch 10: val_accuracy did not improve from 0.43367\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.4062 - loss: 1.6056 - val_accuracy: 0.4335 - val_loss: 1.5177\n",
      "Epoch 11/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - accuracy: 0.3932 - loss: 1.5738\n",
      "Epoch 11: val_accuracy improved from 0.43367 to 0.43527, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 1s/step - accuracy: 0.3932 - loss: 1.5737 - val_accuracy: 0.4353 - val_loss: 1.4877\n",
      "Epoch 12/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:24\u001b[0m 970ms/step - accuracy: 0.3281 - loss: 1.6535\n",
      "Epoch 12: val_accuracy did not improve from 0.43527\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.3281 - loss: 1.6535 - val_accuracy: 0.4340 - val_loss: 1.4870\n",
      "Epoch 13/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - accuracy: 0.4238 - loss: 1.5076\n",
      "Epoch 13: val_accuracy improved from 0.43527 to 0.47066, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 1s/step - accuracy: 0.4238 - loss: 1.5075 - val_accuracy: 0.4707 - val_loss: 1.4301\n",
      "Epoch 14/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:29\u001b[0m 977ms/step - accuracy: 0.5156 - loss: 1.1787\n",
      "Epoch 14: val_accuracy improved from 0.47066 to 0.47290, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5156 - loss: 1.1787 - val_accuracy: 0.4729 - val_loss: 1.4225\n",
      "Epoch 15/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - accuracy: 0.4452 - loss: 1.4533\n",
      "Epoch 15: val_accuracy improved from 0.47290 to 0.48581, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 1s/step - accuracy: 0.4452 - loss: 1.4533 - val_accuracy: 0.4858 - val_loss: 1.3303\n",
      "Epoch 16/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:50\u001b[0m 1s/step - accuracy: 0.5000 - loss: 1.3437\n",
      "Epoch 16: val_accuracy improved from 0.48581 to 0.48629, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 1.3437 - val_accuracy: 0.4863 - val_loss: 1.3351\n",
      "Epoch 17/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993ms/step - accuracy: 0.4699 - loss: 1.3942\n",
      "Epoch 17: val_accuracy improved from 0.48629 to 0.48948, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 1s/step - accuracy: 0.4699 - loss: 1.3942 - val_accuracy: 0.4895 - val_loss: 1.3491\n",
      "Epoch 18/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:55\u001b[0m 1s/step - accuracy: 0.4531 - loss: 1.5068\n",
      "Epoch 18: val_accuracy improved from 0.48948 to 0.49235, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.4531 - loss: 1.5068 - val_accuracy: 0.4923 - val_loss: 1.3387\n",
      "Epoch 19/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - accuracy: 0.4777 - loss: 1.3627\n",
      "Epoch 19: val_accuracy improved from 0.49235 to 0.55182, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 1s/step - accuracy: 0.4777 - loss: 1.3627 - val_accuracy: 0.5518 - val_loss: 1.1851\n",
      "Epoch 20/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:34\u001b[0m 983ms/step - accuracy: 0.5938 - loss: 1.0575\n",
      "Epoch 20: val_accuracy did not improve from 0.55182\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.5938 - loss: 1.0575 - val_accuracy: 0.5501 - val_loss: 1.1857\n",
      "Epoch 21/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994ms/step - accuracy: 0.4968 - loss: 1.3238\n",
      "Epoch 21: val_accuracy did not improve from 0.55182\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 1s/step - accuracy: 0.4968 - loss: 1.3238 - val_accuracy: 0.5179 - val_loss: 1.2831\n",
      "Epoch 22/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:24\u001b[0m 970ms/step - accuracy: 0.5469 - loss: 1.1494\n",
      "Epoch 22: val_accuracy did not improve from 0.55182\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.5469 - loss: 1.1494 - val_accuracy: 0.5124 - val_loss: 1.2969\n",
      "Epoch 23/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995ms/step - accuracy: 0.5112 - loss: 1.2909\n",
      "Epoch 23: val_accuracy improved from 0.55182 to 0.56457, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 1s/step - accuracy: 0.5112 - loss: 1.2908 - val_accuracy: 0.5646 - val_loss: 1.1513\n",
      "Epoch 24/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:30\u001b[0m 978ms/step - accuracy: 0.4531 - loss: 1.4656\n",
      "Epoch 24: val_accuracy improved from 0.56457 to 0.56553, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.4531 - loss: 1.4656 - val_accuracy: 0.5655 - val_loss: 1.1433\n",
      "Epoch 25/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995ms/step - accuracy: 0.5175 - loss: 1.2664\n",
      "Epoch 25: val_accuracy improved from 0.56553 to 0.58211, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 1s/step - accuracy: 0.5175 - loss: 1.2664 - val_accuracy: 0.5821 - val_loss: 1.0943\n",
      "Epoch 26/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:31\u001b[0m 980ms/step - accuracy: 0.6719 - loss: 1.1752\n",
      "Epoch 26: val_accuracy improved from 0.58211 to 0.58498, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6719 - loss: 1.1752 - val_accuracy: 0.5850 - val_loss: 1.0844\n",
      "Epoch 27/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - accuracy: 0.5277 - loss: 1.2452\n",
      "Epoch 27: val_accuracy did not improve from 0.58498\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 1s/step - accuracy: 0.5277 - loss: 1.2452 - val_accuracy: 0.5595 - val_loss: 1.1665\n",
      "Epoch 28/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:31\u001b[0m 979ms/step - accuracy: 0.6250 - loss: 1.0033\n",
      "Epoch 28: val_accuracy did not improve from 0.58498\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 1.0033 - val_accuracy: 0.5660 - val_loss: 1.1526\n",
      "Epoch 29/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - accuracy: 0.5469 - loss: 1.2025\n",
      "Epoch 29: val_accuracy improved from 0.58498 to 0.59152, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 1s/step - accuracy: 0.5469 - loss: 1.2025 - val_accuracy: 0.5915 - val_loss: 1.0586\n",
      "Epoch 30/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:18\u001b[0m 961ms/step - accuracy: 0.4844 - loss: 1.3010\n",
      "Epoch 30: val_accuracy did not improve from 0.59152\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.4844 - loss: 1.3010 - val_accuracy: 0.5912 - val_loss: 1.0608\n",
      "Epoch 31/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - accuracy: 0.5509 - loss: 1.1832\n",
      "Epoch 31: val_accuracy improved from 0.59152 to 0.60061, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.5509 - loss: 1.1832 - val_accuracy: 0.6006 - val_loss: 1.0596\n",
      "Epoch 32/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:21\u001b[0m 966ms/step - accuracy: 0.5156 - loss: 1.2699\n",
      "Epoch 32: val_accuracy improved from 0.60061 to 0.60108, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5156 - loss: 1.2699 - val_accuracy: 0.6011 - val_loss: 1.0577\n",
      "Epoch 33/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - accuracy: 0.5558 - loss: 1.1719\n",
      "Epoch 33: val_accuracy did not improve from 0.60108\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.5558 - loss: 1.1719 - val_accuracy: 0.5950 - val_loss: 1.0726\n",
      "Epoch 34/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:33\u001b[0m 982ms/step - accuracy: 0.4688 - loss: 1.2663\n",
      "Epoch 34: val_accuracy did not improve from 0.60108\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.4688 - loss: 1.2663 - val_accuracy: 0.5952 - val_loss: 1.0696\n",
      "Epoch 35/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - accuracy: 0.5611 - loss: 1.1539\n",
      "Epoch 35: val_accuracy improved from 0.60108 to 0.61209, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.5611 - loss: 1.1539 - val_accuracy: 0.6121 - val_loss: 1.0244\n",
      "Epoch 36/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:48\u001b[0m 1s/step - accuracy: 0.6250 - loss: 1.1058\n",
      "Epoch 36: val_accuracy did not improve from 0.61209\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 1.1058 - val_accuracy: 0.6114 - val_loss: 1.0264\n",
      "Epoch 37/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5711 - loss: 1.1266\n",
      "Epoch 37: val_accuracy improved from 0.61209 to 0.63217, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 1s/step - accuracy: 0.5711 - loss: 1.1266 - val_accuracy: 0.6322 - val_loss: 0.9686\n",
      "Epoch 38/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:39\u001b[0m 991ms/step - accuracy: 0.6250 - loss: 1.1647\n",
      "Epoch 38: val_accuracy did not improve from 0.63217\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 1.1647 - val_accuracy: 0.6314 - val_loss: 0.9695\n",
      "Epoch 39/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - accuracy: 0.5794 - loss: 1.1201\n",
      "Epoch 39: val_accuracy improved from 0.63217 to 0.63441, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 1s/step - accuracy: 0.5794 - loss: 1.1200 - val_accuracy: 0.6344 - val_loss: 0.9666\n",
      "Epoch 40/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:36\u001b[0m 986ms/step - accuracy: 0.5781 - loss: 1.0992\n",
      "Epoch 40: val_accuracy improved from 0.63441 to 0.63457, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5781 - loss: 1.0992 - val_accuracy: 0.6346 - val_loss: 0.9646\n",
      "Epoch 41/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995ms/step - accuracy: 0.5857 - loss: 1.0980\n",
      "Epoch 41: val_accuracy did not improve from 0.63457\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 1s/step - accuracy: 0.5857 - loss: 1.0980 - val_accuracy: 0.6132 - val_loss: 1.0234\n",
      "Epoch 42/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:37\u001b[0m 987ms/step - accuracy: 0.6406 - loss: 1.0205\n",
      "Epoch 42: val_accuracy did not improve from 0.63457\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6406 - loss: 1.0205 - val_accuracy: 0.6122 - val_loss: 1.0297\n",
      "Epoch 43/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.5895 - loss: 1.0823\n",
      "Epoch 43: val_accuracy did not improve from 0.63457\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.5895 - loss: 1.0823 - val_accuracy: 0.6223 - val_loss: 0.9808\n",
      "Epoch 44/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:36\u001b[0m 987ms/step - accuracy: 0.6094 - loss: 0.9847\n",
      "Epoch 44: val_accuracy did not improve from 0.63457\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6094 - loss: 0.9847 - val_accuracy: 0.6252 - val_loss: 0.9717\n",
      "Epoch 45/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000ms/step - accuracy: 0.5929 - loss: 1.0706\n",
      "Epoch 45: val_accuracy improved from 0.63457 to 0.64238, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.5929 - loss: 1.0706 - val_accuracy: 0.6424 - val_loss: 0.9337\n",
      "Epoch 46/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:48\u001b[0m 1s/step - accuracy: 0.5469 - loss: 1.1349\n",
      "Epoch 46: val_accuracy improved from 0.64238 to 0.64349, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5469 - loss: 1.1349 - val_accuracy: 0.6435 - val_loss: 0.9306\n",
      "Epoch 47/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997ms/step - accuracy: 0.6021 - loss: 1.0525\n",
      "Epoch 47: val_accuracy did not improve from 0.64349\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 1s/step - accuracy: 0.6021 - loss: 1.0525 - val_accuracy: 0.6429 - val_loss: 0.9480\n",
      "Epoch 48/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:52\u001b[0m 1s/step - accuracy: 0.6250 - loss: 1.0430\n",
      "Epoch 48: val_accuracy did not improve from 0.64349\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6250 - loss: 1.0430 - val_accuracy: 0.6424 - val_loss: 0.9520\n",
      "Epoch 49/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6062 - loss: 1.0414\n",
      "Epoch 49: val_accuracy did not improve from 0.64349\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 1s/step - accuracy: 0.6062 - loss: 1.0414 - val_accuracy: 0.6304 - val_loss: 0.9562\n",
      "Epoch 50/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:56\u001b[0m 1s/step - accuracy: 0.6875 - loss: 0.9755\n",
      "Epoch 50: val_accuracy did not improve from 0.64349\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6875 - loss: 0.9755 - val_accuracy: 0.6309 - val_loss: 0.9571\n",
      "Epoch 51/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997ms/step - accuracy: 0.6116 - loss: 1.0285\n",
      "Epoch 51: val_accuracy improved from 0.64349 to 0.66645, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.6115 - loss: 1.0285 - val_accuracy: 0.6665 - val_loss: 0.8979\n",
      "Epoch 52/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:52\u001b[0m 1s/step - accuracy: 0.6406 - loss: 0.9661\n",
      "Epoch 52: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6406 - loss: 0.9661 - val_accuracy: 0.6652 - val_loss: 0.9002\n",
      "Epoch 53/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6167 - loss: 1.0187\n",
      "Epoch 53: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 1s/step - accuracy: 0.6167 - loss: 1.0187 - val_accuracy: 0.6516 - val_loss: 0.9142\n",
      "Epoch 54/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:49\u001b[0m 1s/step - accuracy: 0.4844 - loss: 1.1521\n",
      "Epoch 54: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.4844 - loss: 1.1521 - val_accuracy: 0.6532 - val_loss: 0.9093\n",
      "Epoch 55/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6173 - loss: 1.0086\n",
      "Epoch 55: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6173 - loss: 1.0086 - val_accuracy: 0.6491 - val_loss: 0.9261\n",
      "Epoch 56/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:55\u001b[0m 1s/step - accuracy: 0.6719 - loss: 0.9905\n",
      "Epoch 56: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6719 - loss: 0.9905 - val_accuracy: 0.6483 - val_loss: 0.9299\n",
      "Epoch 57/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - accuracy: 0.6229 - loss: 0.9952\n",
      "Epoch 57: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.6229 - loss: 0.9952 - val_accuracy: 0.6569 - val_loss: 0.9106\n",
      "Epoch 58/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:15\u001b[0m 1s/step - accuracy: 0.5312 - loss: 1.0722\n",
      "Epoch 58: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.5312 - loss: 1.0722 - val_accuracy: 0.6550 - val_loss: 0.9141\n",
      "Epoch 59/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6274 - loss: 0.9853\n",
      "Epoch 59: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m941s\u001b[0m 1s/step - accuracy: 0.6274 - loss: 0.9853 - val_accuracy: 0.6642 - val_loss: 0.8847\n",
      "Epoch 60/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:46\u001b[0m 1s/step - accuracy: 0.6250 - loss: 1.0270\n",
      "Epoch 60: val_accuracy did not improve from 0.66645\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 1.0270 - val_accuracy: 0.6655 - val_loss: 0.8801\n",
      "Epoch 61/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6369 - loss: 0.9630\n",
      "Epoch 61: val_accuracy improved from 0.66645 to 0.66677, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 1s/step - accuracy: 0.6369 - loss: 0.9630 - val_accuracy: 0.6668 - val_loss: 0.8817\n",
      "Epoch 62/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:34\u001b[0m 983ms/step - accuracy: 0.6719 - loss: 0.8322\n",
      "Epoch 62: val_accuracy did not improve from 0.66677\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6719 - loss: 0.8322 - val_accuracy: 0.6666 - val_loss: 0.8797\n",
      "Epoch 63/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.6451 - loss: 0.9536\n",
      "Epoch 63: val_accuracy improved from 0.66677 to 0.67554, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6451 - loss: 0.9536 - val_accuracy: 0.6755 - val_loss: 0.8584\n",
      "Epoch 64/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:37\u001b[0m 988ms/step - accuracy: 0.6875 - loss: 0.8816\n",
      "Epoch 64: val_accuracy improved from 0.67554 to 0.67714, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 0.8816 - val_accuracy: 0.6771 - val_loss: 0.8578\n",
      "Epoch 65/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6400 - loss: 0.9540\n",
      "Epoch 65: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6400 - loss: 0.9540 - val_accuracy: 0.6363 - val_loss: 0.9587\n",
      "Epoch 66/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:52\u001b[0m 1s/step - accuracy: 0.6094 - loss: 0.9684\n",
      "Epoch 66: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6094 - loss: 0.9684 - val_accuracy: 0.6325 - val_loss: 0.9664\n",
      "Epoch 67/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6415 - loss: 0.9468\n",
      "Epoch 67: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 1s/step - accuracy: 0.6415 - loss: 0.9468 - val_accuracy: 0.6693 - val_loss: 0.8689\n",
      "Epoch 68/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:19\u001b[0m 963ms/step - accuracy: 0.5781 - loss: 0.9712\n",
      "Epoch 68: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.5781 - loss: 0.9712 - val_accuracy: 0.6714 - val_loss: 0.8610\n",
      "Epoch 69/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.6466 - loss: 0.9370\n",
      "Epoch 69: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.6466 - loss: 0.9370 - val_accuracy: 0.6510 - val_loss: 0.9250\n",
      "Epoch 70/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:56\u001b[0m 1s/step - accuracy: 0.7656 - loss: 0.8100\n",
      "Epoch 70: val_accuracy did not improve from 0.67714\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.7656 - loss: 0.8100 - val_accuracy: 0.6500 - val_loss: 0.9235\n",
      "Epoch 71/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6514 - loss: 0.9246\n",
      "Epoch 71: val_accuracy improved from 0.67714 to 0.67969, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6514 - loss: 0.9246 - val_accuracy: 0.6797 - val_loss: 0.8456\n",
      "Epoch 72/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:50\u001b[0m 1s/step - accuracy: 0.6719 - loss: 0.9209\n",
      "Epoch 72: val_accuracy improved from 0.67969 to 0.68272, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6719 - loss: 0.9209 - val_accuracy: 0.6827 - val_loss: 0.8365\n",
      "Epoch 73/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6508 - loss: 0.9172\n",
      "Epoch 73: val_accuracy improved from 0.68272 to 0.69292, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 1s/step - accuracy: 0.6508 - loss: 0.9172 - val_accuracy: 0.6929 - val_loss: 0.8244\n",
      "Epoch 74/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:45\u001b[0m 1000ms/step - accuracy: 0.6094 - loss: 1.0525\n",
      "Epoch 74: val_accuracy improved from 0.69292 to 0.69356, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6094 - loss: 1.0525 - val_accuracy: 0.6936 - val_loss: 0.8247\n",
      "Epoch 75/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6533 - loss: 0.9136\n",
      "Epoch 75: val_accuracy did not improve from 0.69356\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6533 - loss: 0.9136 - val_accuracy: 0.6854 - val_loss: 0.8388\n",
      "Epoch 76/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:05\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.9100\n",
      "Epoch 76: val_accuracy did not improve from 0.69356\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.6562 - loss: 0.9100 - val_accuracy: 0.6832 - val_loss: 0.8430\n",
      "Epoch 77/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6668 - loss: 0.8990\n",
      "Epoch 77: val_accuracy did not improve from 0.69356\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6667 - loss: 0.8990 - val_accuracy: 0.6883 - val_loss: 0.8333\n",
      "Epoch 78/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:04\u001b[0m 1s/step - accuracy: 0.6719 - loss: 0.9251\n",
      "Epoch 78: val_accuracy did not improve from 0.69356\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6719 - loss: 0.9251 - val_accuracy: 0.6886 - val_loss: 0.8361\n",
      "Epoch 79/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6660 - loss: 0.8911\n",
      "Epoch 79: val_accuracy improved from 0.69356 to 0.70217, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6660 - loss: 0.8911 - val_accuracy: 0.7022 - val_loss: 0.8020\n",
      "Epoch 80/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:37\u001b[0m 988ms/step - accuracy: 0.6250 - loss: 0.9115\n",
      "Epoch 80: val_accuracy did not improve from 0.70217\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 0.9115 - val_accuracy: 0.7003 - val_loss: 0.8027\n",
      "Epoch 81/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6586 - loss: 0.8943\n",
      "Epoch 81: val_accuracy did not improve from 0.70217\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6586 - loss: 0.8943 - val_accuracy: 0.7012 - val_loss: 0.7991\n",
      "Epoch 82/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:41\u001b[0m 994ms/step - accuracy: 0.6406 - loss: 1.0342\n",
      "Epoch 82: val_accuracy improved from 0.70217 to 0.70265, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6406 - loss: 1.0342 - val_accuracy: 0.7026 - val_loss: 0.8006\n",
      "Epoch 83/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6643 - loss: 0.8893\n",
      "Epoch 83: val_accuracy improved from 0.70265 to 0.70934, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6643 - loss: 0.8893 - val_accuracy: 0.7093 - val_loss: 0.7804\n",
      "Epoch 84/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:00\u001b[0m 1s/step - accuracy: 0.5938 - loss: 1.0696\n",
      "Epoch 84: val_accuracy improved from 0.70934 to 0.71110, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.5938 - loss: 1.0696 - val_accuracy: 0.7111 - val_loss: 0.7769\n",
      "Epoch 85/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.6702 - loss: 0.8753\n",
      "Epoch 85: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6702 - loss: 0.8753 - val_accuracy: 0.7044 - val_loss: 0.7897\n",
      "Epoch 86/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:54\u001b[0m 1s/step - accuracy: 0.6406 - loss: 0.9116\n",
      "Epoch 86: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6406 - loss: 0.9116 - val_accuracy: 0.7050 - val_loss: 0.7852\n",
      "Epoch 87/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6711 - loss: 0.8713\n",
      "Epoch 87: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6711 - loss: 0.8713 - val_accuracy: 0.7044 - val_loss: 0.7999\n",
      "Epoch 88/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:43\u001b[0m 997ms/step - accuracy: 0.6250 - loss: 0.9404\n",
      "Epoch 88: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 0.9404 - val_accuracy: 0.7033 - val_loss: 0.7997\n",
      "Epoch 89/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.6767 - loss: 0.8621\n",
      "Epoch 89: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 1s/step - accuracy: 0.6767 - loss: 0.8621 - val_accuracy: 0.6987 - val_loss: 0.8028\n",
      "Epoch 90/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:48\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.9425\n",
      "Epoch 90: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6562 - loss: 0.9425 - val_accuracy: 0.7020 - val_loss: 0.8019\n",
      "Epoch 91/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6789 - loss: 0.8520\n",
      "Epoch 91: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6789 - loss: 0.8520 - val_accuracy: 0.6765 - val_loss: 0.8561\n",
      "Epoch 92/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:00\u001b[0m 1s/step - accuracy: 0.7812 - loss: 0.7977\n",
      "Epoch 92: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.7812 - loss: 0.7977 - val_accuracy: 0.6789 - val_loss: 0.8520\n",
      "Epoch 93/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6752 - loss: 0.8572\n",
      "Epoch 93: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 1s/step - accuracy: 0.6752 - loss: 0.8572 - val_accuracy: 0.7076 - val_loss: 0.7907\n",
      "Epoch 94/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:18\u001b[0m 1s/step - accuracy: 0.6875 - loss: 0.9010\n",
      "Epoch 94: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 0.9010 - val_accuracy: 0.7095 - val_loss: 0.7882\n",
      "Epoch 95/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - accuracy: 0.6787 - loss: 0.8520\n",
      "Epoch 95: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6787 - loss: 0.8520 - val_accuracy: 0.7020 - val_loss: 0.7937\n",
      "Epoch 96/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:56\u001b[0m 1s/step - accuracy: 0.6719 - loss: 0.8332\n",
      "Epoch 96: val_accuracy did not improve from 0.71110\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6719 - loss: 0.8332 - val_accuracy: 0.7038 - val_loss: 0.7959\n",
      "Epoch 97/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000ms/step - accuracy: 0.6814 - loss: 0.8457\n",
      "Epoch 97: val_accuracy improved from 0.71110 to 0.72545, saving model to model_E100_weights.h5.keras\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 1s/step - accuracy: 0.6814 - loss: 0.8457 - val_accuracy: 0.7254 - val_loss: 0.7445\n",
      "Epoch 98/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:18\u001b[0m 961ms/step - accuracy: 0.6406 - loss: 0.8316\n",
      "Epoch 98: val_accuracy did not improve from 0.72545\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6406 - loss: 0.8316 - val_accuracy: 0.7245 - val_loss: 0.7436\n",
      "Epoch 99/100\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6844 - loss: 0.8367\n",
      "Epoch 99: val_accuracy did not improve from 0.72545\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 1s/step - accuracy: 0.6844 - loss: 0.8367 - val_accuracy: 0.6926 - val_loss: 0.8321\n",
      "Epoch 100/100\n",
      "\u001b[1m  1/707\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:52\u001b[0m 1s/step - accuracy: 0.6719 - loss: 0.8104\n",
      "Epoch 100: val_accuracy did not improve from 0.72545\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.6719 - loss: 0.8104 - val_accuracy: 0.6945 - val_loss: 0.8257\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "# number of epochs to train the NN\n",
    "epochs = 100\n",
    "\n",
    "# checkpoint to save best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_E100_weights.h5.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e200d00-f898-4b37-9506-c57c7858681b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
